{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies for BERT model\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer architecture code\n",
    "def get_bert_embeddings(text):\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    # Tokenize input\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    # Convert token to vocabulary indices\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    # Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    # Load pre-trained model (weights)\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    model.eval()\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "    token_embeddings.size()\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    token_embeddings.size()\n",
    "    # Swap dimensions 0 and 1.\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    token_embeddings.size()\n",
    "    # `encoded_layers` is a Python list.\n",
    "    # Each layer in the list is a torch tensor.\n",
    "    # Each tensor has the shape [number of tokens x number of hidden units]\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    # Swap dimensions 0 and 1.\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    # Stores the token vectors, with shape [22 x 12 x 768]\n",
    "    token_vecs_cat = []\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "        # `token` is a [12 x 768] tensor\n",
    "        # Concatenate the vectors (that is, append them together) from the last four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat.append(cat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git large files issue\n",
    "# https://www.youtube.com/watch?v=TXSmxtU2tOk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def transform_date_format(dates):\n",
    "    transformed_dates = []\n",
    "    for date_str in dates:\n",
    "        try:\n",
    "            date = datetime.strptime(date_str, \"%Y/%m/%d\")\n",
    "            transformed_dates.append(date.strftime(\"%Y/%d/%m\"))\n",
    "\n",
    "        except ValueError:\n",
    "            try:\n",
    "                date = datetime.strptime(date_str, \"%m-%d-%Y\")\n",
    "                transformed_dates.append(date.strftime(\"%Y%d%m\"))\n",
    "\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    date = datetime.strptime(date_str.replace(\" \", \"\"), \"%Y%D%M%p\")\n",
    "                    transformed_dates.append(date.strftime(\"%Y%d%m\"))\n",
    "\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "    return transformed_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/20/02\n",
      "20121811\n"
     ]
    }
   ],
   "source": [
    "dates = transform_date_format([\"2010/02/20\", \"2 016p 19p 12\", \"11-18-2012\", \"2018 12 24\", \"20130720\"])\n",
    "print(*dates, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
